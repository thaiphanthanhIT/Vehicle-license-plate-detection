{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPhUkqDaZIhf9b69JU1eyTu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YOy4Ei6R-UN9","executionInfo":{"status":"ok","timestamp":1734382274427,"user_tz":-420,"elapsed":10334,"user":{"displayName":"29. Phan Thanh Thái","userId":"16393740781372431318"}},"outputId":"69d84577-a6fa-4b1d-d0a4-ff55a20d5b65"},"outputs":[{"output_type":"stream","name":"stdout","text":["  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["pip install -q git+https://github.com/THU-MIG/yolov10.git"]},{"cell_type":"code","source":["!wget -P /content/ https://github.com/THU-MIG/yolov10/releases/download/v1.1/yolov10n.pt\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5YVXc1U_-6SD","executionInfo":{"status":"ok","timestamp":1734382312014,"user_tz":-420,"elapsed":2656,"user":{"displayName":"29. Phan Thanh Thái","userId":"16393740781372431318"}},"outputId":"a0912701-bd27-4587-fbc5-37b65edffa96"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-12-16 20:51:53--  https://github.com/THU-MIG/yolov10/releases/download/v1.1/yolov10n.pt\n","Resolving github.com (github.com)... 20.27.177.113\n","Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/804788522/411e0d4f-1023-40ad-bfdd-c99f0dddb73b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241216%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241216T205154Z&X-Amz-Expires=300&X-Amz-Signature=29ab07dc1864abee586cd41e869899b22dcb06d31887963293d84f09f51bbaec&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolov10n.pt&response-content-type=application%2Foctet-stream [following]\n","--2024-12-16 20:51:54--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/804788522/411e0d4f-1023-40ad-bfdd-c99f0dddb73b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241216%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241216T205154Z&X-Amz-Expires=300&X-Amz-Signature=29ab07dc1864abee586cd41e869899b22dcb06d31887963293d84f09f51bbaec&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolov10n.pt&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 11448431 (11M) [application/octet-stream]\n","Saving to: ‘/content/yolov10n.pt’\n","\n","yolov10n.pt         100%[===================>]  10.92M  16.7MB/s    in 0.7s    \n","\n","2024-12-16 20:51:56 (16.7 MB/s) - ‘/content/yolov10n.pt’ saved [11448431/11448431]\n","\n"]}]},{"cell_type":"code","source":["from ultralytics import YOLOv10\n"],"metadata":{"id":"RUm2_QwV_qb2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#load data\n","%cd /content/data\n","\n","!unzip dataset.zip\n","\n","%cd /content/data\n","!mkdir train\n","!mkdir train/images\n","!mkdir train/labels\n","!mv *.jpg train/images\n","!mv *.txt train/labels\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"mISyNNSaFGJ-","executionInfo":{"status":"ok","timestamp":1734382363043,"user_tz":-420,"elapsed":12596,"user":{"displayName":"29. Phan Thanh Thái","userId":"16393740781372431318"}},"outputId":"c3816347-6a8b-417e-9141-b99235d9d58c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/data\n","Archive:  dataset.zip\n","replace dataset/0000_00532_b.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: /content/data\n","mkdir: cannot create directory ‘train’: File exists\n","mkdir: cannot create directory ‘train/images’: File exists\n","mkdir: cannot create directory ‘train/labels’: File exists\n","mv: cannot stat '*.jpg': No such file or directory\n","mv: cannot stat '*.txt': No such file or directory\n"]}]},{"cell_type":"code","source":["%cd /content/data/dataset\n","!mkdir train2\n","!mkdir train2/images\n","!mkdir train2/labels"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xfyehzjFR30T","executionInfo":{"status":"ok","timestamp":1734383232081,"user_tz":-420,"elapsed":652,"user":{"displayName":"29. Phan Thanh Thái","userId":"16393740781372431318"}},"outputId":"46d5b2bc-4270-411b-e599-e34cbd00a785"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/data/dataset\n","mv: target 'train/images' is not a directory\n","mv: target 'train/labels' is not a directory\n"]}]},{"cell_type":"code","source":["!mv *.jpg train2/images\n","!mv *.txt train2/labels"],"metadata":{"id":"2oWCYbHwTCIc","executionInfo":{"status":"ok","timestamp":1734383251443,"user_tz":-420,"elapsed":1197,"user":{"displayName":"29. Phan Thanh Thái","userId":"16393740781372431318"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["%cd /content/data\n","!rm mydataset.yaml\n","!echo 'name:' >> mydataset.yaml\n","!echo ' - BienSo' >> mydataset.yaml\n","!echo 'nc: 1' >> mydataset.yaml\n","!echo 'train: /content/data/train' >> mydataset.yaml\n","!echo 'test: /content/data/train' >> mydataset.yaml\n","!echo 'val: /content/data/train' >> mydataset.yaml\n","\n"],"metadata":{"id":"4Wxts-MoHeWV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!yolo task=detect mode=train epochs=20 batch=32 data='/content/data/mydataset.yaml' model='/content/yolov10n.pt'  plots=True"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ABDcqVM_JOpf","executionInfo":{"status":"ok","timestamp":1734384895624,"user_tz":-420,"elapsed":1599550,"user":{"displayName":"29. Phan Thanh Thái","userId":"16393740781372431318"}},"outputId":"e97f5b6f-446a-4a5b-bfd5-3bfd8de6f7de"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  ckpt = torch.load(file, map_location=\"cpu\")\n","New https://pypi.org/project/ultralytics/8.3.50 available 😃 Update with 'pip install -U ultralytics'\n","Ultralytics YOLOv8.1.34 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/content/yolov10n.pt, data=/content/data/mydataset.yaml, epochs=20, time=None, patience=100, batch=32, imgsz=640, save=True, save_period=-1, val_period=1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n","2024-12-16 21:08:26.904173: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-12-16 21:08:26.925179: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-12-16 21:08:26.931248: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","Overriding model.yaml nc=80 with nc=1\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1      9856  ultralytics.nn.modules.block.SCDown          [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1    249728  ultralytics.nn.modules.block.PSA             [256, 256]                    \n"," 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 13                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 16                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 19                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 20                  -1  1     18048  ultralytics.nn.modules.block.SCDown          [128, 128, 3, 2]              \n"," 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 22                  -1  1    282624  ultralytics.nn.modules.block.C2fCIB          [384, 256, 1, True, True]     \n"," 23        [16, 19, 22]  1    861718  ultralytics.nn.modules.head.v10Detect        [1, [64, 128, 256]]           \n","YOLOv10n summary: 385 layers, 2707430 parameters, 2707414 gradients, 8.4 GFLOPs\n","\n","Transferred 493/595 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n","\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n","Freezing layer 'model.23.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n.pt to 'yolov8n.pt'...\n","100% 6.23M/6.23M [00:00<00:00, 16.7MB/s]\n","/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  ckpt = torch.load(file, map_location=\"cpu\")\n","/usr/local/lib/python3.10/dist-packages/ultralytics/utils/checks.py:641: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(True):\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py:276: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data/dataset/train2/labels... 2490 images, 0 backgrounds, 0 corrupt: 100% 2490/2490 [00:01<00:00, 1876.07it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data/dataset/train2/labels.cache\n","/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.22 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n","  check_for_updates()\n","/usr/local/lib/python3.10/dist-packages/albumentations/core/composition.py:205: UserWarning: Got processor for bboxes, but no transform to process it.\n","  self._set_keys()\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data/dataset/train2/labels.cache... 2490 images, 0 backgrounds, 0 corrupt: 100% 2490/2490 [00:00<?, ?it/s]\n","Plotting labels to runs/detect/train/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 95 weight(decay=0.0), 108 weight(decay=0.0005), 107 bias(decay=0.0)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/detect/train\u001b[0m\n","Starting training for 20 epochs...\n","\n","      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n","       1/20      5.63G     0.9186      1.612      1.139     0.9284      5.281      1.072         45        640: 100% 78/78 [00:56<00:00,  1.39it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 39/39 [00:21<00:00,  1.84it/s]\n","                   all       2490       2490          1      0.278      0.827      0.635\n","\n","      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n","       2/20      5.63G     0.8553     0.8277      1.065     0.9077      2.524      1.036         42        640: 100% 78/78 [00:53<00:00,  1.46it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 39/39 [00:21<00:00,  1.82it/s]\n","                   all       2490       2490      0.892      0.877      0.958      0.756\n","\n","      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n","       3/20      5.63G     0.8612     0.6482      1.061     0.9249      1.373      1.033         43        640: 100% 78/78 [00:53<00:00,  1.47it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 39/39 [00:21<00:00,  1.83it/s]\n","                   all       2490       2490       0.91      0.882      0.964      0.761\n","\n","      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n","       4/20      5.63G     0.8491     0.5372      1.049     0.9132     0.8206      1.028         55        640: 100% 78/78 [00:52<00:00,  1.49it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 39/39 [00:23<00:00,  1.69it/s]\n","                   all       2490       2490      0.902      0.924      0.974       0.75\n","\n","      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n","       5/20      5.58G       0.84     0.4885      1.044     0.8967     0.6246      1.009         39        640: 100% 78/78 [00:51<00:00,  1.51it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 39/39 [00:23<00:00,  1.65it/s]\n","                   all       2490       2490      0.926       0.93      0.979      0.782\n","\n","      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n","       6/20      5.58G     0.8179     0.4601      1.028     0.8758     0.5287     0.9991         49        640: 100% 78/78 [00:51<00:00,  1.50it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 39/39 [00:22<00:00,  1.75it/s]\n","                   all       2490       2490      0.943       0.95      0.988      0.798\n","\n","      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n","       7/20      5.58G     0.8024     0.4276      1.021      0.861     0.4693     0.9923         59        640: 100% 78/78 [00:53<00:00,  1.46it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 39/39 [00:20<00:00,  1.88it/s]\n","                   all       2490       2490      0.926      0.933      0.981      0.771\n","\n","      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n","       8/20      5.58G     0.7848     0.4076      1.015     0.8316     0.4354     0.9809         47        640: 100% 78/78 [00:56<00:00,  1.39it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 39/39 [00:20<00:00,  1.90it/s]\n","                   all       2490       2490      0.967      0.928      0.988      0.795\n","\n","      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n","       9/20      5.58G     0.7944     0.4049      1.022     0.8418        0.4      0.987         42        640: 100% 78/78 [00:53<00:00,  1.47it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 39/39 [00:21<00:00,  1.85it/s]\n","                   all       2490       2490      0.962      0.962       0.99      0.791\n","\n","      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n","      10/20      5.58G     0.7906     0.3955      1.017     0.8356     0.3958     0.9833         52        640: 100% 78/78 [00:53<00:00,  1.46it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 39/39 [00:22<00:00,  1.70it/s]\n","                   all       2490       2490      0.951      0.964       0.99       0.79\n","Closing dataloader mosaic\n","/usr/local/lib/python3.10/dist-packages/albumentations/core/composition.py:205: UserWarning: Got processor for bboxes, but no transform to process it.\n","  self._set_keys()\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n","      11/20      5.58G     0.7674      0.359      1.015     0.7904     0.3126     0.9804         26        640: 100% 78/78 [00:52<00:00,  1.47it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 39/39 [00:20<00:00,  1.86it/s]\n","                   all       2490       2490      0.962      0.978      0.993        0.8\n","\n","      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n","      12/20      5.58G      0.764     0.3587      1.017     0.7863     0.3024     0.9827         26        640: 100% 78/78 [00:49<00:00,  1.59it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 39/39 [00:21<00:00,  1.85it/s]\n","                   all       2490       2490      0.969      0.956      0.991       0.81\n","\n","      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n","      13/20      5.58G     0.7487     0.3409      1.014     0.7677     0.2812     0.9767         26        640: 100% 78/78 [00:53<00:00,  1.46it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 39/39 [00:21<00:00,  1.79it/s]\n","                   all       2490       2490      0.972      0.974      0.993       0.81\n","\n","      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n","      14/20      5.58G     0.7375     0.3248       1.01      0.758     0.2773     0.9749         26        640: 100% 78/78 [00:48<00:00,  1.62it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 39/39 [00:21<00:00,  1.84it/s]\n","                   all       2490       2490      0.968      0.971      0.992       0.81\n","\n","      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n","      15/20      5.58G     0.7389     0.3229      1.006     0.7526     0.2579      0.961         26        640: 100% 78/78 [00:49<00:00,  1.58it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 39/39 [00:20<00:00,  1.87it/s]\n","                   all       2490       2490      0.982      0.973      0.994      0.813\n","\n","      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n","      16/20      5.58G     0.7279     0.3198      1.001     0.7445     0.2476     0.9595         26        640: 100% 78/78 [00:53<00:00,  1.46it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 39/39 [00:20<00:00,  1.88it/s]\n","                   all       2490       2490      0.974      0.978      0.994      0.818\n","\n","      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n","      17/20      5.58G     0.7212     0.3093     0.9978     0.7338     0.2495     0.9619         26        640: 100% 78/78 [00:51<00:00,  1.51it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 39/39 [00:21<00:00,  1.85it/s]\n","                   all       2490       2490      0.968      0.977      0.993      0.818\n","\n","      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n","      18/20      5.58G     0.7121     0.2993     0.9938     0.7237     0.2327     0.9606         26        640: 100% 78/78 [00:49<00:00,  1.56it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 39/39 [00:22<00:00,  1.77it/s]\n","                   all       2490       2490      0.987      0.975      0.994      0.821\n","\n","      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n","      19/20      5.58G     0.7127     0.2893     0.9861     0.7203     0.2359     0.9514         26        640: 100% 78/78 [00:52<00:00,  1.50it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 39/39 [00:22<00:00,  1.75it/s]\n","                   all       2490       2490      0.971      0.984      0.994      0.821\n","\n","      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n","      20/20      5.58G     0.7016     0.2813     0.9817      0.713     0.2298     0.9454         26        640: 100% 78/78 [00:48<00:00,  1.60it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 39/39 [00:22<00:00,  1.73it/s]\n","                   all       2490       2490      0.981      0.981      0.994      0.824\n","\n","20 epochs completed in 0.425 hours.\n","Optimizer stripped from runs/detect/train/weights/last.pt, 5.7MB\n","Optimizer stripped from runs/detect/train/weights/best.pt, 5.7MB\n","\n","Validating runs/detect/train/weights/best.pt...\n","Ultralytics YOLOv8.1.34 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","YOLOv10n summary (fused): 285 layers, 2694806 parameters, 0 gradients, 8.2 GFLOPs\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 39/39 [00:23<00:00,  1.67it/s]\n","                   all       2490       2490      0.981      0.981      0.994      0.824\n","Speed: 0.2ms preprocess, 3.3ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/detect/train\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ▃▆███▇▇▆▆▅▅▅▄▄▃▃▂▂▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▃▆███▇▇▆▆▅▅▅▄▄▃▃▂▂▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▃▆███▇▇▆▆▅▅▅▄▄▃▃▂▂▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▆▇▇▇█▇█████████████\n","\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▅▆▅▆▇▆▇▇▇▇▇▇▇██████\n","\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) █▁▂▂▃▄▃▆▆▅▆▆▆▆▇▆▆▇▆▇\n","\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▇▇▇▇██▇████████████\n","\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/box_om █▆▆▆▅▅▄▄▄▄▃▃▃▂▂▂▂▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/box_oo █▇██▇▆▆▅▅▅▄▃▃▂▂▂▂▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/cls_om █▄▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/cls_oo █▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/dfl_om █▅▅▄▄▃▃▂▃▃▂▃▂▂▂▂▂▂▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/dfl_oo █▆▆▆▅▄▄▃▃▃▃▃▃▃▂▂▂▂▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:              val/box_om █▆▇▇▆▅▇▅▅▅▅▄▃▃▃▂▂▂▂▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:              val/box_oo ▆▆▅█▄▄▆▄▄▄▄▃▂▂▃▂▂▂▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:              val/cls_om █▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:              val/cls_oo █▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:              val/dfl_om █▄▅▅▄▃▅▃▃▃▃▂▂▂▂▂▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:              val/dfl_oo █▆▇█▄▃▅▃▃▃▃▂▂▂▂▁▂▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.00022\n","\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.00022\n","\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.00022\n","\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.99422\n","\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.82444\n","\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.98059\n","\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.98112\n","\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 8.394\n","\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 2707430\n","\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 3.515\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/box_om 0.70158\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/box_oo 0.71296\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/cls_om 0.28126\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/cls_oo 0.22976\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/dfl_om 0.98174\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/dfl_oo 0.9454\n","\u001b[34m\u001b[1mwandb\u001b[0m:              val/box_om 0.68614\n","\u001b[34m\u001b[1mwandb\u001b[0m:              val/box_oo 0.6918\n","\u001b[34m\u001b[1mwandb\u001b[0m:              val/cls_om 0.2607\n","\u001b[34m\u001b[1mwandb\u001b[0m:              val/cls_oo 0.22272\n","\u001b[34m\u001b[1mwandb\u001b[0m:              val/dfl_om 0.96016\n","\u001b[34m\u001b[1mwandb\u001b[0m:              val/dfl_oo 0.93465\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /content/data/dataset/wandb/offline-run-20241216_210834-eop4cdpe\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20241216_210834-eop4cdpe/logs\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/train\n"]}]},{"cell_type":"code","source":["from ultralytics import YOLOv10\n","%cd /content\n","model_path = \"/content/data/dataset/runs/detect/train/weights/best.pt\"\n","model = YOLOv10(model_path)\n","\n","results = model(source=\"/content/0000_00532_b.jpg\", conf = 0.25, save = True)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mr8cjygSZDMz","executionInfo":{"status":"ok","timestamp":1734385223742,"user_tz":-420,"elapsed":5,"user":{"displayName":"29. Phan Thanh Thái","userId":"16393740781372431318"}},"outputId":"d5c0bf52-585f-4a94-c0c4-5e572aaba399"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  ckpt = torch.load(file, map_location=\"cpu\")\n"]},{"output_type":"stream","name":"stdout","text":["image 1/1 /content/0000_00532_b.jpg: 416x640 1 class_0, 17.1ms\n","Speed: 1.7ms preprocess, 17.1ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","Results saved to \u001b[1mruns/detect/predict\u001b[0m\n"]}]}]}